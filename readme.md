# Musical Emotion

## Autores

Carlos A. Cancino Escobar: [C4ncino](https://github.com/C4ncino)

Juan Pablo G√≥mez Haro Cabrera: [JuanPabloGHC](https://github.com/JuanPabloGHC)

## Introducci√≥n

Este proyecto desarrolla una soluci√≥n con Inteligencia Artificial y el uso de las API's de OpenAI y de Spotify, para reconocer tu estado de √°nimo a trav√©s de captura de video y de acuerdo a tu estado de √°nimo te recomienda 5 canciones para levantarte el √°nimo o mantenerte en uno alegre, reproduciendo las canciones en tu aplicaci√≥n de spotify.

## Tecnolog√≠as

- Tensorflow
  - Facilita la creaci√≥n de modelos de aprendizaje autom√°tico para computadoras de escritorio, dispositivos m√≥viles, la web y la nube, sin importar si eres principiante o experto.
- OpenAI API
  - Ofrece la flexibilidad para personalizar las respuestas de tu chatbot, permiti√©ndote infundir la personalidad deseada en cada interacci√≥n. Esto se logra ajustando los par√°metros de los modelos de lenguaje, como el tono y el estilo de las respuestas.
- Sppotipy API
  - Permite acceder a los datos y las funcionalidades del servicio de m√∫sica en streaming en otras aplicaciones.
- Dotenv
  - Uso de variables de entorno.
- Webbrowser
  - Poder acceder a sitios web o aplicaciones dentro de la computadora.
- Pyautogui
  - Controlar acciones del teclado.
- Cv2
  - Uso de la c√°mara y dataset de reconocimiento facial.

## Dataset

**Conjunto de datos de im√°genes de reconocimiento de emociones faciales**

- Emociones
  - Happy
  - Neutral
  - Angry
  - Sad
  - Sorprendido

1. dataset.zip contains folders with corresponding classes.
2. data.csv contains pathes to images and corresponding labels.

Kovenko, Volodymyr; Shevchuk, Vitalii (2021), ‚ÄúOAHEGA : EMOTION RECOGNITION DATASET‚Äù, Mendeley Data, V2, doi: 10.17632/5ck5zz6f2c.2

[P√°gina oficial](https://www.kaggle.com/datasets/sujaykapadnis/emotion-recognition-dataset)

## Arquitectura

```plain
‚îú‚îÄ‚îÄüìÅ/documentation
‚îÇ   ‚îî‚îÄ‚îÄüìÅ/images
‚îÇ       ‚îú‚îÄ‚îÄüñºÔ∏è[im√°genes de loss]
|       ‚îî‚îÄ‚îÄüñºÔ∏è[im√°genes de accuracy]
‚îÇ
‚îú‚îÄ‚îÄüìÅ/models
‚îÇ   ‚îî‚îÄ‚îÄüìÑ[versiones de modelos de IA entrenados]
‚îÇ
‚îú‚îÄ‚îÄüêçapp.py
‚îú‚îÄ‚îÄüìù.env
‚îú‚îÄ‚îÄüêçbasic_use.py
‚îú‚îÄ‚îÄüêçrecomendation.py
‚îú‚îÄ‚îÄüêçtrain.py
‚îî‚îÄ‚îÄüìùrequirements.txt
```

- /documentation:
  - Im√°genes para documentar el proceso y resultados del entrenamiento, tanto el loss y el accuracy de cada modelo que se gener√≥.
- /models:
  - Modelos guardados por versiones previamente entrenados.
- app.py:
  - Programa principal que ejecuta todo el programa.
- .env:
  - Se almacenan las variables de entorno, para almacenar los tokens y credenciales de las API's, se tiene el .env.example como ejemplo.
- basic_use.py:
  - C√≥digo para la captura de video, procesamiento de imagen y la predicci√≥n del estado de √°nimo.
- recomendation.py:
  - C√≥digo para hacer uso de la API de openai para la recomendaci√≥n de m√∫sica de acuerdo a tu estado de √°nimo y posteriormente reproducirlas en la aplicaci√≥n de spotify con su API.
- requirements.txt:
  - Las dependencias que se utilizar√≥n en el proyecto.

## Limitantes

- Se necesita tener instalada la aplicaci√≥n de Spotify en la computadora para reproducir la m√∫sica.

- Si deseas entrenar un modelo, es necesario utilizar una computadora con suficientes recursos ya que llegan a ser muy tardados por ser una red neuronal convolucional.

## Instalaci√≥n

- Clonar el repositorio.
- Moverte a la carpeta del proyecto.
- Instalar todas las dependencias.

```bash
git clone https://github.com/C4ncino/Musical_Emotions.git

cd Musical_Emotions
```

En la instalaci√≥n de dependencias recomendamos tener un entorno virtual en caso de que no desees uno puedes ir directo a la instalaci√≥n de [dependencias](#dependencies), para crearlo ejecuta lo siguiente:

```bash
python -m venv venv
```

La activaci√≥n del entorno virtual depende de su sistema operativo:

Linux:

```bash
source venv/bin/activate
```

Windows:

```bash
venv\Scripts\activate
```

Windows con bash:

```bash
source venv\Scripts\activate
```

<span id="dependencies" ></span>

Una vez activado el entorno virtual, se instalan las dependencias:

```bash
pip install -r requirements.txt
```

## Implementaci√≥n de IA

Se us√≥ una red neuronal convulacinoal para el procesamiento y entrenamiento del modelo para reconocimiento de emociones con el uso del dataset y de esta manera poderlo aplicar con el usuario.

## Capa extra de IA mediante la API de OpenAI

Se us√≥ la API para hacerle una petici√≥n de recomendaciones musicales de acuerdo al estado de √°nimo.

- Rol del sistema:
  - Eres un sistema recomendador de m√∫sica de acuerdo al estado de √°nimo. Recomiendas 5 canciones. En caso de tener un √°nimo Tristeza, Enojo, Nuetral, recomiendas m√∫sica que levante el √°nimo de la persona para sentirse mejor. En caso de tener un √°nimo de Alegr√≠a, Asombro, Sorprendido, recomiendas m√∫sica que mantenga ese estado de √°nimo. Solo dame la lista de canciones que se dividan por , cada sugerencia y que se separe el autor de la cancion con un - .
- Contenido:
  - "Estado de √°nimo: <emoci√≥n>"

Adem√°s se us√≥ la API de spotipy para poder acceder a una canci√≥n en espec√≠fico con su artista para poderla reproducir con el uso de su uri y la duraci√≥n de esta para el tiempo de espera entre canci√≥n y canci√≥n.

- Se requieren los tokens y credenciales espec√≠ficas de cada API para su uso.

## Relevancia Social

La propuesta que se tiene es para poder tener un impacto positivo en las emociones de las personas, brindandoles un ambiente agradable en donde la m√∫sica acompa√±e a una persona en su estado de √°nimo, que en caso de ser negativo; ayude en mejorarlo y en caso de ser positivo; ayude a mantenerlo y poderlo expresar de mejor manera.

## Innovaci√≥n y Creatividad

Con el uso de herramientas existentes se unen para brindar una propuesta de una actividad cotidiana, que es el escuchar m√∫sica, para brindar un apoyo r√°pido y lo m√°s acertado para tu estado de √°nimo.

## Modelos y resultados

Para las arquitecturas de las versiones 1, 2 y 3 se utiliz√≥ de capa base el modelo VGG16 de TensorFlow con un input de 224x224x3. las modificaciones que sufrieron se encuentran en las capas posteriores a las convoluciones, as√≠ mismo todas cuentan con una capa de salida de 5 neuronas.

Por otro lado, los modelo del 4 al 6 cuentan con la misma arquitectura, sin embargo en este caso se fue variando entre los inputshape entre 64x64x3 y 128x128x3. Al igual que las √©pocas y el learning rate.

### v1

Arquitectura del modelo

| Tipo de capa | Neuronas | Dropout |
| ------------ | -------- | ------- |
| Densa        | 1024     | 0.4     |
| Densa        | 512      | 0.2     |
| Densa        | 256      | 0.1     |

![](documentation/images/v1.png)

### v2

Arquitectura del modelo

| Tipo de capa | Neuronas | Dropout |
| ------------ | -------- | ------- |
| Densa        | 512      | 0.6     |
| Densa        | 256      | 0.4     |
| Densa        | 256      | 0.4     |
| Densa        | 128      | 0.2     |

Resultados

![](documentation/images/v2.png)
![](documentation/images/acc_v2.png)

### v3

Arquitectura del modelo

| Tipo de capa | Neuronas | Dropout |
| ------------ | -------- | ------- |
| Densa        | 512      | 0.5     |
| Densa        | 256      | 0.25    |
| Densa        | 256      | 0.25    |
| Densa        | 128      | 0.1     |
| Densa        | 32       | -       |

Resultados

![](documentation/images/v3.png)
![](documentation/images/acc_v3.png)

### v4

Arquitectura del modelo

| Capa | Tipo               | Tama√±o/Filtros     | Funci√≥n de Activaci√≥n | Otros                                           |
| ---- | ------------------ | ------------------ | --------------------- | ----------------------------------------------- |
| 1    | Input              | Shape: input_shape | -                     |                                                 |
| 2    | Conv2D             | Filtros: 32        | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 3    | BatchNormalization | -                  | -                     | Axis: -1                                        |
| 4    | Conv2D             | Filtros: 32        | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 5    | BatchNormalization | -                  | -                     | Axis: -1                                        |
|      | MaxPooling2D       | Pool size: (2, 2)  | -                     |                                                 |
|      | Dropout            | Ratio: 0.25        | -                     |                                                 |
| 6    | Conv2D             | Filtros: 64        | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 7    | BatchNormalization | -                  | -                     | Axis: -1                                        |
| 8    | Conv2D             | Filtros: 64        | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 9    | BatchNormalization | -                  | -                     | Axis: -1                                        |
|      | MaxPooling2D       | Pool size: (2, 2)  | -                     |                                                 |
|      | Dropout            | Ratio: 0.25        | -                     |                                                 |
| 10   | Conv2D             | Filtros: 128       | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 11   | BatchNormalization | -                  | -                     | Axis: -1                                        |
| 12   | Conv2D             | Filtros: 128       | ELU                   | Padding: same<br> Kernel initializer: he_normal |
| 13   | BatchNormalization | -                  | -                     | Axis: -1                                        |
|      | MaxPooling2D       | Pool size: (2, 2)  | -                     |                                                 |
|      | Dropout            | Ratio: 0.25        | -                     |                                                 |
|      | Flatten            | -                  | -                     |                                                 |
| 14   | Dense              | Units: 64          | ELU                   | Kernel initializer: he_normal                   |
| 15   | BatchNormalization | -                  | -                     | Axis: -1                                        |
|      | Dropout            | Ratio: 0.5         | -                     |                                                 |
| 16   | Dense              | Units: 64          | ELU                   | Kernel initializer: he_normal                   |
| 17   | BatchNormalization | -                  | -                     | Axis: -1                                        |
|      | Dropout            | Ratio: 0.5         | -                     |                                                 |
| 18   | Dense              | Units: classes     | Softmax               | Kernel initializer: he_normal                   |

Resultados

![](documentation/images/v4.png)
![](documentation/images/acc_v4.png)

### v5 

Resultados

![](documentation/images/v5.png)
![](documentation/images/acc_v5.png)

### v6 

Resultados

![](documentation/images/v6.png)
![](documentation/images/acc_v6.png)
